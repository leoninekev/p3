
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Chapter 01 - Dogs: loglinear model for binary data &#8212; Probabilistic-Programming-with-Pyro</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.e8f53015daec13862f6db5e763c41738.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
      <img src="../../../_static/ppyro_logo.gif" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Probabilistic-Programming-with-Pyro</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../intro.html">
   Probabilitic-Programming-with-Pyro
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Part II
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Ch01_dogs_log_linear_Pyro.html">
   Chapter 01  - Dogs: loglinear model for binary data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Chapter_2/Ch02_stacks_robust_regression_Pyro.html">
   Chapter 02 - Stacks: linear regression model
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../../../_sources/Part_II/Chapter_1/md_files/Ch01_dogs_log_linear_Pyro.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/Part_II/Chapter_1/md_files/Ch01_dogs_log_linear_Pyro.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/mlsquare/p3"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/mlsquare/p3/issues/new?title=Issue%20on%20page%20%2FPart_II/Chapter_1/md_files/Ch01_dogs_log_linear_Pyro.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/mlsquare/p3/master?urlpath=tree/Part_II/Chapter_1/md_files/Ch01_dogs_log_linear_Pyro.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-specification-dogs-model-definition">
   1. Model Specification: Dogs Model definition
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prior-predictive-checking">
   2. Prior predictive checking
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#posterior-estimation">
   3. Posterior estimation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#diagnosing-model-fit">
   4. Diagnosing model fit
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-evaluation-posterior-predictive-checks">
   5. Model evaluation: Posterior predictive checks
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-comparison">
   6. Model Comparison
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-d-alpha-beta-to-compute-dic">
     Using
     <span class="math notranslate nohighlight">
      \(D(\alpha,\beta)\)
     </span>
     to Compute DIC
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="chapter-01-dogs-loglinear-model-for-binary-data">
<h1>Chapter 01  - Dogs: loglinear model for binary data<a class="headerlink" href="#chapter-01-dogs-loglinear-model-for-binary-data" title="Permalink to this headline">¶</a></h1>
<p><strong>Background:</strong> Solomon-Wynne in 1953 conducted an experiment on avoidance learning in dogs from traumatic experiences in past such as those from electric shocks.
The apparatus of experiment holds a dog in a closed compartment with steel flooring, open on side with a small barrier for dog to jump over to the other side. A high-voltage electric shock is discharged into the steel floor intermittently to stimulate the dog; Thus the dog is effectively left with an option to either get the shock for that trial or jump over the barrier to other side &amp; save himself. Several dogs were subjected to similar experiment for many consecutive trials.
This picture elicits the apparatus</p>
<p><img alt="dog_setup" src="../../../_images/avoidance_learning.png" /></p>
<p>The elaborate details of the experiment can be found at
http://www.appstate.edu/~steelekm/classes/psy5300/Documents/Solomon&amp;Wynne%201953.pdf</p>
<p>The hypothesis is that most of the dogs learnt to avoid shocks by jumping over barrier to the other side after suffering the trauma of shock in previous trials. That inturn sustain dogs in future encounters with electric shocks.</p>
<p>Since the experiment aims to study the avoidance learning in dogs from past traumatic experiences and reach a plausible model where dogs learn to avoid scenerios responsible for causing trauma, we describe the phenomenon using expression
$<span class="math notranslate nohighlight">\(
\pi_j   =   A^{xj} B^{j-xj}
\)</span>$
Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\pi_j\)</span> is the probability of a dog getting shocked at trial <span class="math notranslate nohighlight">\(j\)</span></p></li>
<li><p>A &amp; B both are random variables drawing values from Normal distribution</p></li>
<li><p><span class="math notranslate nohighlight">\(x_j\)</span> is number of successful avoidances of shock prior to trial <span class="math notranslate nohighlight">\(j\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(j-x_j\)</span> is number of shocks experienced prior to trial <span class="math notranslate nohighlight">\(j\)</span>.
In the subsequent</p></li>
</ul>
<p>The hypothesis is thus corroborated by Bayesian modelling and comprehensive analysis of dogs data available from Solomon-Wynne experiment in Pyro.</p>
<p>The data is analysed step by step in accordance with Bayesian workflow as described in “Bayesian Workflow”, Prof. Andrew Gelman [http://www.stat.columbia.edu/~gelman/research/unpublished/Bayesian_Workflow_article.pdf].</p>
<p>Import following dependencies.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyro</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>

<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span> <span class="nn">pyro.distributions</span> <span class="k">as</span> <span class="nn">dist</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">pyro.nn</span> <span class="kn">import</span> <span class="n">PyroModule</span>
<span class="kn">from</span> <span class="nn">pyro.infer</span> <span class="kn">import</span> <span class="n">MCMC</span><span class="p">,</span> <span class="n">NUTS</span>


<span class="kn">import</span> <span class="nn">plotly</span>
<span class="kn">import</span> <span class="nn">plotly.express</span> <span class="k">as</span> <span class="nn">px</span>
<span class="kn">import</span> <span class="nn">plotly.figure_factory</span> <span class="k">as</span> <span class="nn">ff</span>

<span class="n">pyro</span><span class="o">.</span><span class="n">set_rng_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Uncomment following if pandas available with plotly backend</span>

<span class="c1"># pd.options.plotting.backend = &quot;plotly&quot;</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;default&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="model-specification-dogs-model-definition">
<h2>1. Model Specification: Dogs Model definition<a class="headerlink" href="#model-specification-dogs-model-definition" title="Permalink to this headline">¶</a></h2>
<hr class="docutils" />
<div class="math notranslate nohighlight">
\[
\pi_j   =   A^{xj} B^{j-xj}
\]</div>
<p>We intend to find most probable values for parameters <span class="math notranslate nohighlight">\(\alpha\)</span> &amp; <span class="math notranslate nohighlight">\(\beta\)</span> (dubbed as random variable A &amp; B respectively) in the expression to compute likelihood (<span class="math notranslate nohighlight">\(\pi_j\)</span>) of dogs getting shocked.</p>
<p><strong>Generative model for resulting likelihood of shock:</strong></p>
<p><span class="math notranslate nohighlight">\(\pi_j\)</span>  ~   <span class="math notranslate nohighlight">\(bern\ (\exp \ (\alpha.XAvoidance + \beta.XShocked)\ )\)</span>,  <span class="math notranslate nohighlight">\(prior\ \alpha\)</span> ~ <span class="math notranslate nohighlight">\(N(0., 316.)\)</span>,  <span class="math notranslate nohighlight">\(\beta\)</span> ~ <span class="math notranslate nohighlight">\(N(0., 316.)\)</span></p>
<p>The above expression is used as a generalised linear model with log-link function in WinBugs implementation</p>
<p><strong>BUGS model</strong></p>
<p><span class="math notranslate nohighlight">\(\log\pi_j = \alpha\ x_j + \beta\ ( \)</span>j<span class="math notranslate nohighlight">\(-x_j )\)</span></p>
<p><strong>Here</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\log\pi_j\)</span> is log probability of a dog getting shocked at trial <span class="math notranslate nohighlight">\(j\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(x_j\)</span> is number of successful avoidances of shock prior to trial <span class="math notranslate nohighlight">\(j\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(j-x_j\)</span> is number of shocks experienced prior to trial <span class="math notranslate nohighlight">\(j\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span> is the coefficient corresponding to number of success, <span class="math notranslate nohighlight">\(\beta\)</span> is the coefficient corresponding to number of failures.</p></li>
</ul>
<hr class="docutils" />
<p>The same model when implemented in PyStan</p>
<p><strong>Equivalent Stan model</strong></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>  {

  alpha ~ normal(0.0, 316.2);

  beta  ~ normal(0.0, 316.2);

  for(dog in 1:Ndogs)

    for (trial in 2:Ntrials)  

      y[dog, trial] ~ bernoulli(exp(alpha * xa[dog, trial] + beta * 
      xs[dog, trial]));
  
  }
</pre></div>
</div>
<p><strong>Model implementation</strong></p>
<p>The model is defined using Pyro as per the expression of generative model for this dataset as follows</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dogs model with normal prior</span>
<span class="k">def</span> <span class="nf">DogsModel</span><span class="p">(</span><span class="n">x_avoidance</span><span class="p">,</span> <span class="n">x_shocked</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Input</span>
<span class="sd">    -------</span>
<span class="sd">    x_avoidance: tensor holding avoidance count for all dogs &amp; all trials, example for </span>
<span class="sd">                 30 dogs &amp; 25 trials, shaped (30, 25)</span>
<span class="sd">    x_shocked:   tensor holding shock count for all dogs &amp; all trials, example for 30 dogs</span>
<span class="sd">                 &amp; 25 trials, shaped (30, 25).</span>
<span class="sd">    y:           tensor holding response for all dogs &amp; trials, example for 30 dogs</span>
<span class="sd">                 &amp; 25 trials, shaped (30, 25).</span>
<span class="sd">    </span>
<span class="sd">    Output</span>
<span class="sd">    --------</span>
<span class="sd">    Implements pystan model: {</span>
<span class="sd">              alpha ~ normal(0.0, 316.2);</span>
<span class="sd">              beta  ~ normal(0.0, 316.2);</span>
<span class="sd">              for(dog in 1:Ndogs)  </span>
<span class="sd">                for (trial in 2:Ntrials)  </span>
<span class="sd">                  y[dog, trial] ~ bernoulli(exp(alpha * xa[dog, trial] + beta * xs[dog, trial]));}</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;alpha&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">316.</span><span class="p">))</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;beta&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mi">316</span><span class="p">))</span>
    <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">):</span>
        <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;obs&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">alpha</span><span class="o">*</span><span class="n">x_avoidance</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">x_shocked</span><span class="p">)),</span> <span class="n">obs</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Dogs data</strong></p>
<p>Following holds the Dogs data in the pystan modelling format</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dogs_data</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Ndogs&quot;</span><span class="p">:</span><span class="mi">30</span><span class="p">,</span> 
             <span class="s2">&quot;Ntrials&quot;</span><span class="p">:</span><span class="mi">25</span><span class="p">,</span> 
             <span class="s2">&quot;Y&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> 
                  <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> 
                  <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> 
                  <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> 
                  <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                  <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                  <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                  <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> 
                  <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                  <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                  <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                  <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                  <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                  <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                  <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                  <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                  <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                  <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">30</span><span class="p">,</span><span class="mi">25</span><span class="p">))}</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Following processes target label <code class="docutils literal notranslate"><span class="pre">y</span></code> to obtain input data <code class="docutils literal notranslate"><span class="pre">x_avoidance</span></code> &amp; <code class="docutils literal notranslate"><span class="pre">x_shocked</span></code> where:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">x_avoidance</span></code> :  number of shock avoidances before current trial.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">x_shocked</span></code> :  number of shocks before current trial.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">transform_data</span><span class="p">(</span><span class="n">Ndogs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">Ntrials</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Input</span>
<span class="sd">    -------</span>
<span class="sd">    Ndogs: Total number of Dogs i.e., 30</span>
<span class="sd">    Ntrials: Total number of Trials i.e., 25</span>
<span class="sd">    Y: Raw responses from data, example: np.array([0, 0, 0, 0])</span>
<span class="sd">    </span>
<span class="sd">    Outputs</span>
<span class="sd">    ---------</span>
<span class="sd">    xa: tensor holding avoidance count for all dogs &amp; all trials</span>
<span class="sd">    xs: tensor holding shock count for all dogs &amp; all trials</span>
<span class="sd">    y: tensor holding response observation for all dogs &amp; all trials</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Ndogs</span><span class="p">,</span> <span class="n">Ntrials</span><span class="p">))</span>
    <span class="n">xa</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Ndogs</span><span class="p">,</span> <span class="n">Ntrials</span><span class="p">))</span>
    <span class="n">xs</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Ndogs</span><span class="p">,</span> <span class="n">Ntrials</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">dog</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Ndogs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">trial</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">Ntrials</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">xa</span><span class="p">[</span><span class="n">dog</span><span class="p">,</span> <span class="n">trial</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">dog</span><span class="p">,</span> <span class="p">:</span><span class="n">trial</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="c1">#Number of successful avoidances uptill previous trial</span>
            <span class="n">xs</span><span class="p">[</span><span class="n">dog</span><span class="p">,</span> <span class="n">trial</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span> <span class="n">trial</span> <span class="o">-</span><span class="mi">1</span> <span class="o">-</span> <span class="n">xa</span><span class="p">[</span><span class="n">dog</span><span class="p">,</span> <span class="n">trial</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1">#Number of shocks uptill previous trial</span>
    <span class="k">for</span> <span class="n">dog</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Ndogs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">trial</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Ntrials</span><span class="p">):</span>
            <span class="n">y</span><span class="p">[</span><span class="n">dog</span><span class="p">,</span> <span class="n">trial</span><span class="p">]</span><span class="o">=</span> <span class="mi">1</span><span class="o">-</span> <span class="n">Y</span><span class="p">[</span><span class="n">dog</span><span class="p">,</span> <span class="n">trial</span><span class="p">]</span>
    <span class="n">xa</span><span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">xa</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
    <span class="n">xs</span><span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>  
    <span class="n">y</span><span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">xa</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Here the py-stan format data (python dictionary) is passed to the function above, in order to preprocess it to tensor format required for pyro sampling</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x_avoidance</span><span class="p">,</span> <span class="n">x_shocked</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span> <span class="n">transform_data</span><span class="p">(</span><span class="o">**</span><span class="n">dogs_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x_avoidance: </span><span class="si">%s</span><span class="s2">, x_shocked: </span><span class="si">%s</span><span class="s2">, y: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">x_avoidance</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x_shocked</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Sample x_avoidance: </span><span class="si">%s</span><span class="s2"> </span><span class="se">\n\n</span><span class="s2">Sample x_shocked: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">x_avoidance</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">x_shocked</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="prior-predictive-checking">
<h2>2. Prior predictive checking<a class="headerlink" href="#prior-predictive-checking" title="Permalink to this headline">¶</a></h2>
<p>These checks help to understand the implications of a prior distributions of underlying parameters (random variables) in the context of a given generative model by simulating from the model rather than observed data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">priors_list</span><span class="o">=</span> <span class="p">[(</span><span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;alpha&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">316.</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> 
               <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;beta&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">316.</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1100</span><span class="p">)]</span><span class="c1"># Picking 1100 prior samples</span>

<span class="n">prior_samples</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;alpha&quot;</span><span class="p">:</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">prior_pair</span><span class="p">:</span><span class="n">prior_pair</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">priors_list</span><span class="p">)),</span> <span class="s2">&quot;beta&quot;</span><span class="p">:</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">prior_pair</span><span class="p">:</span><span class="n">prior_pair</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">priors_list</span><span class="p">))}</span>
</pre></div>
</div>
</div>
</div>
<p>Sampled output of prior values for alpha &amp; beta is stored in <code class="docutils literal notranslate"><span class="pre">prior_samples</span></code> above, and is plotted on a KDE plot as follows:</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Following is an interactive plot, can be visualised fully in Binder.</p>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">ff</span><span class="o">.</span><span class="n">create_distplot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">prior_samples</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="nb">list</span><span class="p">(</span><span class="n">prior_samples</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Prior distribution of parameters&quot;</span><span class="p">,</span> <span class="n">xaxis_title</span><span class="o">=</span><span class="s2">&quot;parameter values&quot;</span><span class="p">,</span> <span class="n">yaxis_title</span><span class="o">=</span><span class="s2">&quot;density&quot;</span><span class="p">,</span> <span class="n">legend_title</span><span class="o">=</span><span class="s2">&quot;parameters&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Prior alpha Q(0.5) :</span><span class="si">%s</span><span class="s2"> | Prior beta Q(0.5) :</span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">prior_samples</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">],</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">prior_samples</span><span class="p">[</span><span class="s2">&quot;beta&quot;</span><span class="p">],</span> <span class="mf">0.5</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="posterior-estimation">
<h2>3. Posterior estimation<a class="headerlink" href="#posterior-estimation" title="Permalink to this headline">¶</a></h2>
<p>In the parlance of probability theory, Posterior implies the probability of updated beliefs in regard to a quantity or parameter of interest, in the wake of given evidences and prior information.</p>
<div class="math notranslate nohighlight">
\[Posterior = \frac {Likelihood x Prior}{Probability \ of Evidence}\]</div>
<p>For the parameters of interest <span class="math notranslate nohighlight">\(\alpha,\beta\)</span> &amp; evidence y; Posterior can be denoted as <span class="math notranslate nohighlight">\(P\ (\alpha,\beta\ /\ y)\)</span>.</p>
<div class="math notranslate nohighlight">
\[P\ (\alpha,\beta\ /\ y) = \frac {P\ (y /\ \alpha,\beta) P(\alpha,\beta)}{P(y)}\]</div>
<p>Posterior, <span class="math notranslate nohighlight">\(P\ (\alpha,\beta\ /\ y)\)</span> in regard to this experiment is the likelihood of parameter values (i.e., Coefficient of instances avoided dubbed retention ability &amp; Coefficient of instances shocked dubbed learning ability) given the observed instances <code class="docutils literal notranslate"><span class="pre">y</span></code> of getting shocked. Where <span class="math notranslate nohighlight">\(P(\alpha,\beta)\)</span> is prior information/likelihood of parameter values.</p>
<p>The following intakes a pyro model object with defined priors, input data and some configuration in regard to chain counts &amp; chain length prior to launching a <code class="docutils literal notranslate"><span class="pre">MCMC</span> <span class="pre">NUTs</span> <span class="pre">sampler</span></code> and outputs MCMC chained samples in a python dictionary format.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_hmc_n_chains</span><span class="p">(</span><span class="n">pyromodel</span><span class="p">,</span> <span class="n">xa</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">num_chains</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">base_count</span> <span class="o">=</span> <span class="mi">900</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Input</span>
<span class="sd">    -------</span>
<span class="sd">    pyromodel: Pyro model object with specific prior distribution</span>
<span class="sd">    xa: tensor holding avoidance count for all dogs &amp; all trials</span>
<span class="sd">    xs: tensor holding shock count for all dogs &amp; all trials</span>
<span class="sd">    y: tensor holding response observation for all dogs &amp; all trials</span>
<span class="sd">    num_chains: Count of MCMC chains to launch, default 4</span>
<span class="sd">    base_count:Minimum count of samples in a MCMC chains , default 900</span>
<span class="sd">    </span>
<span class="sd">    Ouputs</span>
<span class="sd">    ---------</span>
<span class="sd">    hmc_sample_chains: a dictionary with chain names as keys &amp; dictionary of parameter vs sampled values list as values </span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">hmc_sample_chains</span> <span class="o">=</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>
    <span class="n">possible_samples_list</span><span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">base_count</span><span class="p">,</span> <span class="n">base_count</span><span class="o">+</span><span class="n">num_chains</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">)),</span> <span class="n">num_chains</span><span class="p">)</span>
    <span class="n">possible_burnin_list</span><span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">50</span><span class="p">)),</span> <span class="n">num_chains</span><span class="p">)</span>

    <span class="n">t1</span><span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">possible_samples_list</span><span class="p">,</span> <span class="n">possible_burnin_list</span><span class="p">))):</span>
        <span class="n">num_samples</span><span class="p">,</span> <span class="n">burnin</span><span class="o">=</span> <span class="n">val</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">val</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">nuts_kernel</span> <span class="o">=</span> <span class="n">NUTS</span><span class="p">(</span><span class="n">pyromodel</span><span class="p">)</span>
        <span class="n">mcmc</span> <span class="o">=</span> <span class="n">MCMC</span><span class="p">(</span><span class="n">nuts_kernel</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="o">=</span><span class="n">burnin</span><span class="p">)</span>
        <span class="n">mcmc</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">xa</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">hmc_sample_chains</span><span class="p">[</span><span class="s1">&#39;chain_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">)]</span><span class="o">=</span><span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">mcmc</span><span class="o">.</span><span class="n">get_samples</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Total time: &quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">t1</span><span class="p">)</span>
    <span class="n">hmc_sample_chains</span><span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">hmc_sample_chains</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">hmc_sample_chains</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
<span class="n">hmc_sample_chains</span><span class="o">=</span> <span class="n">get_hmc_n_chains</span><span class="p">(</span><span class="n">DogsModel</span><span class="p">,</span> <span class="n">x_avoidance</span><span class="p">,</span> <span class="n">x_shocked</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">num_chains</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">base_count</span> <span class="o">=</span> <span class="mi">900</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">hmc_sample_chains</span></code> holds sampled MCMC values as <code class="docutils literal notranslate"><span class="pre">{&quot;Chain_0&quot;:</span> <span class="pre">{alpha	[-0.20020795,</span> <span class="pre">-0.1829252,</span> <span class="pre">-0.18054989</span> <span class="pre">.</span> <span class="pre">.,],</span> <span class="pre">&quot;beta&quot;:</span> <span class="pre">{}.</span> <span class="pre">.,},</span> <span class="pre">&quot;Chain_1&quot;:</span> <span class="pre">{alpha	[-0.20020795,</span> <span class="pre">-0.1829252,</span> <span class="pre">-0.18054989</span> <span class="pre">.</span> <span class="pre">.,],</span> <span class="pre">&quot;beta&quot;:</span> <span class="pre">{}.</span> <span class="pre">.,}.</span> <span class="pre">.}</span></code></p>
</div>
<div class="section" id="diagnosing-model-fit">
<h2>4. Diagnosing model fit<a class="headerlink" href="#diagnosing-model-fit" title="Permalink to this headline">¶</a></h2>
<p>Model fit diagnosis consists of briefly obtaining core statistical values from sampled outputs and assess the convergence of various chains from the output, before moving onto inferencing or evaluating predictive power of model.</p>
<p>Following plots <strong>Parameter vs. Chain matrix</strong> and optionally saves the dataframe.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">beta_chain_matrix_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">hmc_sample_chains</span><span class="p">)</span>
<span class="c1"># beta_chain_matrix_df.to_csv(&quot;dogs_log_regression_hmc_sample_chains.csv&quot;, index=False)</span>
<span class="n">beta_chain_matrix_df</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Key statistic results as dataframe</strong></p>
<p>Following method maps the values of required statistics, given a list of statistic names</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">all_metric_func_map</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">metric</span><span class="p">,</span> <span class="n">vals</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;mean&quot;</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">vals</span><span class="p">),</span> <span class="s2">&quot;std&quot;</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">vals</span><span class="p">),</span> 
                                            <span class="s2">&quot;25%&quot;</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">vals</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">),</span> 
                                            <span class="s2">&quot;50%&quot;</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">vals</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">),</span> 
                                            <span class="s2">&quot;75%&quot;</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">vals</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">)}</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">metric</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Following outputs the summary of required statistics such as <code class="docutils literal notranslate"><span class="pre">&quot;mean&quot;,</span> <span class="pre">&quot;std&quot;,</span> <span class="pre">&quot;Q(0.25)&quot;,</span> <span class="pre">&quot;Q(0.50)&quot;,</span> <span class="pre">&quot;Q(0.75)&quot;</span></code>, given a list of statistic names</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">key_metrics</span><span class="o">=</span> <span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">,</span> <span class="s2">&quot;25%&quot;</span><span class="p">,</span> <span class="s2">&quot;50%&quot;</span><span class="p">,</span> <span class="s2">&quot;75%&quot;</span><span class="p">]</span>

<span class="n">summary_stats_df_</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">key_metrics</span><span class="p">:</span>
    <span class="n">final_di</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">beta_chain_matrix_df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="n">params_per_column_di</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">beta_chain_matrix_df</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">all_metric_func_map</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="n">x</span><span class="p">)))</span>
        <span class="n">final_di</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">=</span> <span class="n">params_per_column_di</span>
    <span class="n">metric_df_</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">final_di</span><span class="p">)</span>
    <span class="n">metric_df_</span><span class="p">[</span><span class="s2">&quot;parameter&quot;</span><span class="p">]</span><span class="o">=</span> <span class="n">metric</span>
    <span class="n">summary_stats_df_</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">summary_stats_df_</span><span class="p">,</span> <span class="n">metric_df_</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">summary_stats_df_</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">summary_stats_df_</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span> <span class="p">{</span><span class="s2">&quot;index&quot;</span><span class="p">:</span><span class="s2">&quot;metric&quot;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">summary_stats_df_</span><span class="o">.</span><span class="n">set_index</span><span class="p">([</span><span class="s2">&quot;parameter&quot;</span><span class="p">,</span> <span class="s2">&quot;metric&quot;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">summary_stats_df_</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Obtain 5 point Summary statistics (mean, Q1-Q4, Std, ) as tabular data per chain and save the dataframe.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fit_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="k">for</span> <span class="n">chain</span><span class="p">,</span> <span class="n">values</span> <span class="ow">in</span> <span class="n">hmc_sample_chains</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">param_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
    <span class="n">param_df</span><span class="p">[</span><span class="s2">&quot;chain&quot;</span><span class="p">]</span><span class="o">=</span> <span class="n">chain</span>
    <span class="n">fit_df</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">fit_df</span><span class="p">,</span> <span class="n">param_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">fit_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;data/dogs_classification_hmc_samples.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>    
<span class="n">fit_df</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Use/Uncomment following once the results from pyro sampling operation are saved offline</span>
<span class="c1"># fit_df= pd.read_csv(&quot;data/dogs_classification_hmc_samples.csv&quot;)</span>

<span class="n">fit_df</span>
</pre></div>
</div>
</div>
</div>
<p>Following outputs the similar summary of required statistics such as <code class="docutils literal notranslate"><span class="pre">&quot;mean&quot;,</span> <span class="pre">&quot;std&quot;,</span> <span class="pre">&quot;Q(0.25)&quot;,</span> <span class="pre">&quot;Q(0.50)&quot;,</span> <span class="pre">&quot;Q(0.75)&quot;</span></code>, <strong>But in a slightly different format</strong>, given a list of statistic names**</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">summary_stats_df_2</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>

<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">,</span> <span class="s2">&quot;beta&quot;</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">groupdf</span> <span class="ow">in</span> <span class="n">fit_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;chain&quot;</span><span class="p">):</span>
        <span class="n">groupdi</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">groupdf</span><span class="p">[</span><span class="n">param</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>

        <span class="n">values</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">key</span><span class="p">:(</span><span class="n">key</span><span class="p">,</span> <span class="p">[</span><span class="n">groupdi</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)]),</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;std&#39;</span><span class="p">,</span> <span class="s1">&#39;25%&#39;</span><span class="p">,</span> <span class="s1">&#39;50%&#39;</span><span class="p">,</span> <span class="s1">&#39;75%&#39;</span><span class="p">]))</span>
        <span class="n">values</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;parameter&quot;</span><span class="p">:</span> <span class="n">param</span><span class="p">,</span> <span class="s2">&quot;chain&quot;</span><span class="p">:</span><span class="n">name</span><span class="p">})</span>
        <span class="n">summary_stats_df</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
        <span class="n">summary_stats_df_2</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">summary_stats_df_2</span><span class="p">,</span> <span class="n">summary_stats_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">summary_stats_df_2</span><span class="o">.</span><span class="n">set_index</span><span class="p">([</span><span class="s2">&quot;parameter&quot;</span><span class="p">,</span> <span class="s2">&quot;chain&quot;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">summary_stats_df_2</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Following plots sampled parameters values as Boxplots with <code class="docutils literal notranslate"><span class="pre">M</span> <span class="pre">parameters</span></code> side by side on x axis for each of the <code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">chains</span></code></strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">parameters</span><span class="o">=</span> <span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">,</span> <span class="s2">&quot;beta&quot;</span><span class="p">]</span><span class="c1"># All parameters for given model</span>
<span class="n">chains</span><span class="o">=</span> <span class="n">fit_df</span><span class="p">[</span><span class="s2">&quot;chain&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="c1"># Number of chains sampled for given model</span>


<span class="n">func_all_params_per_chain</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">param</span><span class="p">,</span> <span class="n">chain</span><span class="p">:</span> <span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">fit_df</span><span class="p">[</span><span class="n">fit_df</span><span class="p">[</span><span class="s2">&quot;chain&quot;</span><span class="p">]</span><span class="o">==</span><span class="n">chain</span><span class="p">][</span><span class="n">param</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
<span class="n">func_all_chains_per_param</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">chain</span><span class="p">,</span> <span class="n">param</span><span class="p">:</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">chain</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fit_df</span><span class="p">[</span><span class="n">param</span><span class="p">][</span><span class="n">fit_df</span><span class="p">[</span><span class="s2">&quot;chain&quot;</span><span class="p">]</span><span class="o">==</span><span class="n">chain</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>

<span class="n">di_all_params_per_chain</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">param</span><span class="p">:</span> <span class="n">func_all_params_per_chain</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="s2">&quot;chain_0&quot;</span><span class="p">),</span> <span class="n">parameters</span><span class="p">))</span>
<span class="n">di_all_chains_per_param</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">chain</span><span class="p">:</span> <span class="n">func_all_chains_per_param</span><span class="p">(</span><span class="n">chain</span><span class="p">,</span> <span class="s2">&quot;beta&quot;</span><span class="p">),</span> <span class="n">chains</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">plot_parameters_for_n_chains</span><span class="p">(</span><span class="n">chains</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;chain_0&quot;</span><span class="p">],</span> <span class="n">parameters</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;beta0&quot;</span><span class="p">,</span> <span class="s2">&quot;beta1&quot;</span><span class="p">,</span> <span class="s2">&quot;beta2&quot;</span><span class="p">,</span> <span class="s2">&quot;beta3&quot;</span><span class="p">,</span> <span class="s2">&quot;sigma&quot;</span><span class="p">],</span> <span class="n">plotting_cap</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">plot_interactive</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Input</span>
<span class="sd">    --------</span>
<span class="sd">    chains: list of valid chain names, example - [&quot;chain_0&quot;].</span>
<span class="sd">    </span>
<span class="sd">    parameters: list of valid parameters names, example -[&quot;beta0&quot;, &quot;beta1&quot;, &quot;beta2&quot;, &quot;beta3&quot;, &quot;sigma&quot;].</span>
<span class="sd">    </span>
<span class="sd">    plotting_cap: list of Cap on number of chains &amp; Cap on number of parameters to plot, example- [4, 5] </span>
<span class="sd">                  means cap the plotting of number of chains upto 4 &amp; number of parameters upto 5 ONLY,</span>
<span class="sd">                  If at all the list size for Chains &amp; parameters passed increases.</span>
<span class="sd">    </span>
<span class="sd">    plot_interactive: Flag for using Plotly if True, else Seaborn plots for False.</span>
<span class="sd">    </span>
<span class="sd">    </span>
<span class="sd">    output</span>
<span class="sd">    -------</span>
<span class="sd">    Plots box plots for each chain from list of chains with parameters on x axis.</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">chain_cap</span><span class="p">,</span> <span class="n">param_cap</span> <span class="o">=</span> <span class="n">plotting_cap</span><span class="c1">#</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">chains</span><span class="p">)</span><span class="o">&lt;=</span><span class="n">chain_cap</span><span class="p">,</span> <span class="s2">&quot;Cannot plot Number of chains greater than </span><span class="si">%s</span><span class="s2">!&quot;</span><span class="o">%</span><span class="n">chain_cap</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span><span class="o">&lt;=</span><span class="n">param_cap</span><span class="p">,</span> <span class="s2">&quot;Cannot plot Number of parameters greater than </span><span class="si">%s</span><span class="s2">!&quot;</span><span class="o">%</span><span class="n">param_cap</span>
        
        <span class="k">for</span> <span class="n">chain</span> <span class="ow">in</span> <span class="n">chains</span><span class="p">:</span>
            <span class="n">di_all_params_per_chain</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">param</span><span class="p">:</span> <span class="n">func_all_params_per_chain</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">chain</span><span class="p">),</span> <span class="n">parameters</span><span class="p">))</span>
            <span class="n">df_all_params_per_chain</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">di_all_params_per_chain</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">df_all_params_per_chain</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
<span class="c1">#                 raise Exception(&quot;Invalid chain number in context of model!&quot;)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Note: Chain number [</span><span class="si">%s</span><span class="s2">] is Invalid in context of this model!&quot;</span><span class="o">%</span><span class="n">chain</span><span class="p">)</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="n">plot_interactive</span><span class="p">:</span>
                <span class="n">df_all_params_per_chain</span><span class="o">=</span> <span class="n">df_all_params_per_chain</span><span class="o">.</span><span class="n">unstack</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">df_all_params_per_chain</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;level_0&quot;</span><span class="p">:</span><span class="s2">&quot;parameters&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="s2">&quot;values&quot;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">box</span><span class="p">(</span><span class="n">df_all_params_per_chain</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;parameters&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
                <span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">height</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span> <span class="n">title_text</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">chain</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                <span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">df_all_params_per_chain</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">box</span><span class="p">()</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">chain</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="ow">is</span> <span class="ne">AssertionError</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Note: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="n">error</span><span class="p">)</span>
            <span class="n">chains</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">chains</span><span class="p">,</span> <span class="n">chain_cap</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">parameters</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">param_cap</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">plot_parameters_for_n_chains</span><span class="p">(</span><span class="n">chains</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="n">error</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Pass the list of <code class="docutils literal notranslate"><span class="pre">M</span> <span class="pre">parameters</span></code> and list of <code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">chains</span></code>, with <code class="docutils literal notranslate"><span class="pre">plot_interactive</span></code> as <code class="docutils literal notranslate"><span class="pre">True</span> <span class="pre">or</span> <span class="pre">False</span></code> to choose between Plotly or Seaborn</strong></p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Following is an interactive plot, can be visualised fully Only in Binder.</p>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Use plot_interactive=False for Normal seaborn plots offline</span>

<span class="n">plot_parameters_for_n_chains</span><span class="p">(</span><span class="n">chains</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;chain_0&#39;</span><span class="p">,</span> <span class="s1">&#39;chain_1&#39;</span><span class="p">,</span> <span class="s1">&#39;chain_2&#39;</span><span class="p">,</span> <span class="s1">&#39;chain_3&#39;</span><span class="p">],</span> <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span> <span class="n">plot_interactive</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Following plots the <code class="docutils literal notranslate"><span class="pre">joint</span> <span class="pre">distribution</span></code> of <code class="docutils literal notranslate"><span class="pre">pair</span> <span class="pre">of</span> <span class="pre">each</span> <span class="pre">parameter</span></code> sampled values for all chains</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">all_combination_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">combinations</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

<span class="k">for</span> <span class="n">param_combo</span> <span class="ow">in</span> <span class="n">all_combination_params</span><span class="p">:</span>
    <span class="n">param1</span><span class="p">,</span> <span class="n">param2</span><span class="o">=</span> <span class="n">param_combo</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Pyro -- </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">param1</span><span class="si">}</span><span class="s1"> Vs. </span><span class="si">{</span><span class="n">param2</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">))</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">fit_df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">param1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">param2</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span> <span class="s2">&quot;chain&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">param1</span><span class="si">}</span><span class="s1"> Vs. </span><span class="si">{</span><span class="n">param2</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
</pre></div>
</div>
</div>
</div>
<p><strong>Following plots the <code class="docutils literal notranslate"><span class="pre">Pairplot</span> <span class="pre">distribution</span></code> of each parameter with every other parameter’s sampled values</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">fit_df</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span> <span class="s2">&quot;chain&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Following intakes the list of parameters say <code class="docutils literal notranslate"><span class="pre">[&quot;alpha&quot;,</span> <span class="pre">&quot;beta&quot;]</span></code> and plots hexbins for each interaction pair for all possible combinations of parameters <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">&amp;</span> <span class="pre">beta</span></code>.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">hexbin_plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_label</span><span class="p">,</span> <span class="n">y_label</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    </span>
<span class="sd">    Input</span>
<span class="sd">    -------</span>
<span class="sd">    x: Pandas series or list of values to plot on x axis.</span>
<span class="sd">    y: Pandas series or list of values to plot on y axis.</span>
<span class="sd">    x_label: variable name x label. </span>
<span class="sd">    y_label: variable name x label. </span>
<span class="sd">    </span>
<span class="sd">    </span>
<span class="sd">    Output</span>
<span class="sd">    -------</span>
<span class="sd">    Plot Hexbin correlation density plots for given values.</span>
<span class="sd">    </span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">min_x</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">+</span><span class="nb">list</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> <span class="o">-</span> <span class="mf">0.1</span>
    <span class="n">max_x</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">+</span><span class="nb">list</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> <span class="o">+</span> <span class="mf">0.1</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="p">],</span> <span class="p">[</span><span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="p">])</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="p">])</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1"> vs. </span><span class="si">{}</span><span class="s1"> correlation scatterplot&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x_label</span><span class="p">,</span> <span class="n">y_label</span><span class="p">))</span>
    <span class="n">hbin</span><span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">hexbin</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">gridsize</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">mincnt</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Reds</span><span class="p">)</span>
    <span class="n">cb</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">hbin</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">cb</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s1">&#39;occurence_density&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">y_label</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">x_label</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">plot_interaction_hexbins</span><span class="p">(</span><span class="n">fit_df</span><span class="p">,</span> <span class="n">parameters</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">,</span> <span class="s2">&quot;beta&quot;</span><span class="p">]):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    </span>
<span class="sd">    Input</span>
<span class="sd">    -------</span>
<span class="sd">    fit_df: Pandas dataframe containing sampled values across columns with parameter names as column headers</span>
<span class="sd">    parameters: List of parameters for which all combination of hexbins are to be plotted, defaults to [&quot;alpha&quot;, &quot;beta&quot;]</span>
<span class="sd">    </span>
<span class="sd">    </span>
<span class="sd">    Output</span>
<span class="sd">    -------</span>
<span class="sd">    Plots hexbin correlation density plots for each pair of parameter combination.</span>
<span class="sd">        </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">all_combination_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">combinations</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">param1</span><span class="p">,</span> <span class="n">param2</span> <span class="ow">in</span> <span class="n">all_combination_params</span><span class="p">:</span><span class="c1">#Plots interaction between each of two parameters</span>
        <span class="n">hexbin_plot</span><span class="p">(</span><span class="n">fit_df</span><span class="p">[</span><span class="n">param1</span><span class="p">],</span> <span class="n">fit_df</span><span class="p">[</span><span class="n">param2</span><span class="p">],</span> <span class="n">param1</span><span class="p">,</span> <span class="n">param2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Here parameters <code class="docutils literal notranslate"><span class="pre">[&quot;alpha&quot;,</span> <span class="pre">&quot;beta&quot;]</span></code> are passed to plot all possible interaction pair Hexbin plots in between</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plot_interaction_hexbins</span><span class="p">(</span><span class="n">fit_df</span><span class="p">,</span> <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="model-evaluation-posterior-predictive-checks">
<h2>5. Model evaluation: Posterior predictive checks<a class="headerlink" href="#model-evaluation-posterior-predictive-checks" title="Permalink to this headline">¶</a></h2>
<p>Posterior predictive checking helps examine the fit of a model to real data, as the parameter drawn for simulating conditions &amp; regions of interests come from the posterior distribution.</p>
<p><strong>Pick samples from one particular chain of HMC samples say <code class="docutils literal notranslate"><span class="pre">chain_3</span></code></strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">chain</span><span class="p">,</span> <span class="n">samples</span> <span class="ow">in</span> <span class="n">hmc_sample_chains</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">samples</span><span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">param</span><span class="p">:</span> <span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">param</span><span class="p">))),</span> <span class="n">samples</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span><span class="c1"># np array to tensors</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">chain</span><span class="p">,</span> <span class="s2">&quot;Sample count: &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Plot density for parameters from <code class="docutils literal notranslate"><span class="pre">chain_3</span></code> to visualise the spread of sample values from that chain</strong></p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Following is an interactive plot, can be visualised Only in Binder.</p>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">title</span><span class="o">=</span> <span class="s2">&quot;parameter distribution for : </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">chain</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">ff</span><span class="o">.</span><span class="n">create_distplot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">samples</span><span class="o">.</span><span class="n">values</span><span class="p">())),</span> <span class="nb">list</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span> <span class="n">xaxis_title</span><span class="o">=</span><span class="s2">&quot;parameter values&quot;</span><span class="p">,</span> <span class="n">yaxis_title</span><span class="o">=</span><span class="s2">&quot;density&quot;</span><span class="p">,</span> <span class="n">legend_title</span><span class="o">=</span><span class="s2">&quot;parameters&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Alpha Q(0.5) :</span><span class="si">%s</span><span class="s2"> | Beta Q(0.5) :</span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">],</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&quot;beta&quot;</span><span class="p">],</span> <span class="mf">0.5</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Plot density &amp; contours for both parameters from <code class="docutils literal notranslate"><span class="pre">chain_3</span></code> to visualise the joint distribution &amp; region of interest</strong></p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Following is an interactive plot, can be visualised Only in Binder.</p>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
<span class="n">fit_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="k">for</span> <span class="n">chain</span><span class="p">,</span> <span class="n">values</span> <span class="ow">in</span> <span class="n">hmc_sample_chains</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">param_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
    <span class="n">param_df</span><span class="p">[</span><span class="s2">&quot;chain&quot;</span><span class="p">]</span><span class="o">=</span> <span class="n">chain</span>
    <span class="n">fit_df</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">fit_df</span><span class="p">,</span> <span class="n">param_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1">#Choosing samples from chain 3</span>
<span class="n">chain_samples_df</span><span class="o">=</span> <span class="n">fit_df</span><span class="p">[</span><span class="n">fit_df</span><span class="p">[</span><span class="s2">&quot;chain&quot;</span><span class="p">]</span><span class="o">==</span><span class="n">chain</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="c1"># chain is &#39;chain_3&#39; </span>

<span class="n">alpha</span><span class="o">=</span> <span class="n">chain_samples_df</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">beta</span><span class="o">=</span> <span class="n">chain_samples_df</span><span class="p">[</span><span class="s2">&quot;beta&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">colorscale</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;#7A4579&#39;</span><span class="p">,</span> <span class="s1">&#39;#D56073&#39;</span><span class="p">,</span> <span class="s1">&#39;rgb(236,158,105)&#39;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.98</span><span class="p">,</span><span class="mf">0.98</span><span class="p">,</span><span class="mf">0.98</span><span class="p">)]</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">ff</span><span class="o">.</span><span class="n">create_2d_density</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">colorscale</span><span class="o">=</span><span class="n">colorscale</span><span class="p">,</span> <span class="n">hist_color</span><span class="o">=</span><span class="s1">&#39;rgb(255, 255, 150)&#39;</span><span class="p">,</span> <span class="n">point_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span> <span class="s2">&quot;alpha beta joint density plot&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span> <span class="n">xaxis_title</span><span class="o">=</span><span class="s2">&quot;x (alpha)&quot;</span><span class="p">,</span> <span class="n">yaxis_title</span><span class="o">=</span><span class="s2">&quot;y (beta)&quot;</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Note:</strong> The distribution of alpha values are significantly offset to the left from beta values, by almost 13 times; Thus for any given input observation of avoidances or shocked, the likelihood of getting shocked is more influenced by small measure of avoidance than by getting shocked.</p>
<p><strong>Observations:</strong></p>
<p><strong>On observing the spread of alpha &amp; beta values, the parameter beta being less negative &amp; closer to zero can be interpreted as <code class="docutils literal notranslate"><span class="pre">learning</span> <span class="pre">ability</span></code>, i.e., the ability of dog to learn from shock experiences. The increase in number of shocks barely raises the probability of non-avoidance (value of 𝜋𝑗) with little amount. Unless the trials &amp; shocks increase considerably large in progression, it doesn’t mellow down well and mostly stays around 0.9.</strong></p>
<p><strong>Whereas its not the case with alpha, alpha is more negative &amp; farthest from zero. It imparts a significant decline in non-avoidance (𝜋𝑗) even for few instances where dog avoids the shock; therefore alpha can be interpreted as <code class="docutils literal notranslate"><span class="pre">retention</span> <span class="pre">ability</span></code> i.e., the ability to retain the learning from previous shock experiences.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">chain_samples_df</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">(),</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">chain_samples_df</span><span class="p">[</span><span class="s2">&quot;beta&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p><strong>From the contour plot above following region in posterior distribution seems highly plausible for parameters:</strong></p>
<ol class="simple">
<li><p>For alpha, <code class="docutils literal notranslate"><span class="pre">-0.2</span> <span class="pre">&lt;</span> <span class="pre">alpha</span> <span class="pre">&lt;</span> <span class="pre">-0.19</span></code></p></li>
<li><p>For beta <code class="docutils literal notranslate"><span class="pre">-0.0075</span> <span class="pre">&lt;</span> <span class="pre">beta</span> <span class="pre">&lt;</span> <span class="pre">-0.0055</span></code></p></li>
</ol>
<p>Following selects all the pairs of <code class="docutils literal notranslate"><span class="pre">alpha,</span> <span class="pre">beta</span></code> values between the range mentioned above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">select_sample_df</span><span class="o">=</span> <span class="n">chain_samples_df</span><span class="p">[(</span><span class="n">chain_samples_df</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">]</span><span class="o">&lt;-</span><span class="mf">0.19</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">chain_samples_df</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">]</span><span class="o">&gt;-</span><span class="mf">0.2</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">chain_samples_df</span><span class="p">[</span><span class="s2">&quot;beta&quot;</span><span class="p">]</span><span class="o">&lt;-</span><span class="mf">0.0075</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">chain_samples_df</span><span class="p">[</span><span class="s2">&quot;beta&quot;</span><span class="p">]</span><span class="o">&lt;-</span><span class="mf">0.0055</span><span class="p">)]</span>

<span class="c1"># print(select_sample_df.set_index([&quot;alpha&quot;, &quot;beta&quot;]).index)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Count of alpha-beta pairs of interest, from mid region with high desnity in contour plot above (-0.2 &lt; alpha &lt; -0.19, -0.0075 &lt; beta &lt; -0.0055): &quot;</span><span class="p">,</span> <span class="n">select_sample_df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">select_sample_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Picking a case of 3 trials with Y [0,1,1], i.e. Dog is shocked in 1st, Dogs avoids in 2nd &amp; thereafter, effectively having an experience of 1 shock &amp; 1 avoidance. <code class="docutils literal notranslate"><span class="pre">Considering</span> <span class="pre">all</span> <span class="pre">values</span> <span class="pre">of</span> <span class="pre">alpha</span> <span class="pre">&amp;</span> <span class="pre">beta</span> <span class="pre">in</span> <span class="pre">range</span> <span class="pre">-0.2</span> <span class="pre">&lt;</span> <span class="pre">alpha</span> <span class="pre">&lt;</span> <span class="pre">-0.19,</span> <span class="pre">-0.0075</span> <span class="pre">&lt;</span> <span class="pre">beta</span> <span class="pre">&lt;</span> <span class="pre">-0.0055</span></code></strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Y_li</span><span class="o">=</span> <span class="p">[]</span>
<span class="n">Y_val_to_param_dict</span><span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>

<span class="c1"># Value -0.2 &lt; alpha &lt; -0.19, -0.0075 &lt; beta &lt; -0.0055</span>
<span class="k">for</span> <span class="n">rec</span> <span class="ow">in</span> <span class="n">select_sample_df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span><span class="c1"># for -0.2 &lt; alpha &lt; -0.19, -0.0075 &lt; beta &lt; -0.0055</span>
    <span class="n">a</span><span class="p">,</span><span class="n">b</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">rec</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s2">&quot;alpha&quot;</span><span class="p">]),</span> <span class="nb">float</span><span class="p">(</span><span class="n">rec</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s2">&quot;beta&quot;</span><span class="p">])</span>
    <span class="n">res</span><span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="p">),</span> <span class="mi">4</span><span class="p">)</span>
    <span class="n">Y_li</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
    <span class="n">Y_val_to_param_dict</span><span class="p">[</span><span class="n">res</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="nb">round</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span><span class="nb">round</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="mi">5</span><span class="p">)))</span><span class="c1"># Sample-- {0.8047: [(-0.18269378, -0.034562342), (-0.18383412, -0.033494473)], 0.8027: [(-0.18709463, -0.03263992), (-0.18464606, -0.035114493)]}</span>
</pre></div>
</div>
</div>
</div>
<p>In above <code class="docutils literal notranslate"><span class="pre">Y_val_to_param</span></code> is a dictionary that holds value <span class="math notranslate nohighlight">\(\exp^{\alpha +\beta}\)</span> as key and tuple of corresponding <span class="math notranslate nohighlight">\((\alpha, \beta)\)</span> as value.</p>
<p>The following plots the histogram of <span class="math notranslate nohighlight">\(\exp^{\alpha +\beta}\)</span> values obtained as an interaction of selected <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span> values from region of interest.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Following is an interactive plot, can be visualised Only in Binder.</p>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
<span class="n">Y_for_select_sample_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;Y_for -0.2 &lt; alpha &lt; -0.19 &amp; -0.0075 &lt; beta &lt; -0.0055&quot;</span><span class="p">:</span> <span class="n">Y_li</span><span class="p">})</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">Y_for_select_sample_df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span> <span class="s2">&quot;Y_for -0.2 &lt; alpha &lt; -0.19 &amp; -0.0075 &lt; beta &lt; -0.0055&quot;</span><span class="p">)</span>
<span class="n">title</span><span class="o">=</span> <span class="s2">&quot;observed values distribution for params Y_for -0.2 &lt; alpha &lt; -0.19 &amp; -0.0075 &lt; beta &lt; -0.0055&quot;</span>

<span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span> <span class="n">xaxis_title</span><span class="o">=</span><span class="s2">&quot;observed values&quot;</span><span class="p">,</span> <span class="n">yaxis_title</span><span class="o">=</span><span class="s2">&quot;count&quot;</span><span class="p">,</span> <span class="n">legend_title</span><span class="o">=</span><span class="s2">&quot;dogs&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean: </span><span class="si">%s</span><span class="s2"> | Median: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Y_li</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">Y_li</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sorted observed values: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">Y_li</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p><strong>For given experiment of 3 trials, from all the <code class="docutils literal notranslate"><span class="pre">Ys</span></code> with corresponding alpha-beta pairs of interest, pick 3  lower most values of <code class="docutils literal notranslate"><span class="pre">Y</span></code> for instance; Thus selecting its corresponding alpha-beta pairs</strong></p>
<p><strong>Note:</strong> Can add multiple observed values from histogram for comparison.</p>
<p>Corresponding to <code class="docutils literal notranslate"><span class="pre">lowest_obs</span></code> values of <code class="docutils literal notranslate"><span class="pre">Y</span></code>, obtain <code class="docutils literal notranslate"><span class="pre">select_pairs</span></code> as list of correspoding alpha, beta pairs from  <code class="docutils literal notranslate"><span class="pre">Y_val_to_param_dict</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">lowest_obs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">Y_li</span><span class="p">)[:</span><span class="mi">3</span><span class="p">]</span><span class="c1">#[0.8085, 0.8094, 0.8095]# Pick values from above histogram range or sorted list</span>

<span class="n">selected_pairs</span><span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">obs</span><span class="p">:</span> <span class="n">Y_val_to_param_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">obs</span><span class="p">),</span> <span class="n">lowest_obs</span><span class="p">)))</span>
<span class="n">selected_pairs</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Following stores a dictionary of <code class="docutils literal notranslate"><span class="pre">observed</span> <span class="pre">y</span></code> values for pair of alpha-beta parameters</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_obs_y_dict</span><span class="p">(</span><span class="n">select_pairs</span><span class="p">,</span> <span class="n">x_a</span><span class="p">,</span> <span class="n">x_s</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    </span>
<span class="sd">    Input</span>
<span class="sd">    -------</span>
<span class="sd">    select_pairs: pairs of (alpha, beta) selected</span>
<span class="sd">    x_a: array holding avoidance count for all dogs &amp; all trials, example for 30 dogs &amp; 25 trials, shaped (30, 25)</span>
<span class="sd">    x_s: array holding shock count for all dogs &amp; all trials, example for 30 dogs &amp; 25 trials, shaped (30, 25)</span>
<span class="sd">    </span>
<span class="sd">    Output</span>
<span class="sd">    -------</span>
<span class="sd">    </span>
<span class="sd">    Outputs a dictionary with tuple of alpha, beta as key &amp; observerd values of y corresponding to alpha, beta in key</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span> <span class="ow">in</span> <span class="n">select_pairs</span><span class="p">:</span><span class="c1"># pair of alpha, beta</span>
        <span class="n">y_dict</span><span class="p">[(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">alpha</span><span class="o">*</span><span class="n">x_a</span> <span class="o">+</span> <span class="n">beta</span><span class="o">*</span> <span class="n">x_s</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">y_dict</span>


<span class="n">obs_y_dict</span><span class="o">=</span> <span class="n">get_obs_y_dict</span><span class="p">(</span><span class="n">selected_pairs</span><span class="p">,</span> <span class="n">x_avoidance</span><span class="p">,</span> <span class="n">x_shocked</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Alpha-beta pair values as Keys to access corresponding array of inferred observations: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">obs_y_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Following plots scatterplots of <code class="docutils literal notranslate"><span class="pre">observed</span> <span class="pre">y</span></code> values for all 30 dogs for each alpha-beta pair of interest</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_observed_y_given_parameters</span><span class="p">(</span><span class="n">observations_list</span><span class="p">,</span> <span class="n">selected_pairs_list</span><span class="p">,</span> <span class="n">observed_y</span><span class="p">,</span> <span class="n">chain</span><span class="p">,</span> <span class="n">original_obs</span><span class="o">=</span> <span class="p">[]):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    </span>
<span class="sd">    Input</span>
<span class="sd">    -------</span>
<span class="sd">    observations_list:list of observated &#39;y&#39; values from simulated 3 trials experiment computed corresponding </span>
<span class="sd">                      to selected pairs of (alpha, beta)</span>
<span class="sd">    selected_pairs_list: list of alpha, beta pair tuples, example :  [(-0.225, -0.01272), (-0.21844, -0.01442)]</span>
<span class="sd">    </span>
<span class="sd">    observed_y: dict holding observed values correspodning to pair of alpha, beta tuple as key, </span>
<span class="sd">                example: {(-0.225, -0.01272): tensor([[1.0000, 0.9874,..]])}</span>
<span class="sd">    chain: name of the chain from sampler</span>
<span class="sd">    original_obs: original observations/ labels from given data</span>

<span class="sd">    returns  plotly scatter plots with number of trials on X axis &amp; corresponding probability of getting</span>
<span class="sd">    shocked for each pair of (alpha, beta) passed in &#39;selected_pairs_list&#39;.</span>
<span class="sd">    </span>
<span class="sd">    Output</span>
<span class="sd">    --------</span>
<span class="sd">    Plots scatter plot of all observed values of y corresponding to each given pair of alpha, beta</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">obs_column_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;Dog_</span><span class="si">{</span><span class="n">ind</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dogs_data</span><span class="p">[</span><span class="s2">&quot;Ndogs&quot;</span><span class="p">])]</span>
    
    <span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">observations_list</span><span class="p">,</span> <span class="n">selected_pairs_list</span><span class="p">):</span>
        <span class="n">sim_y</span><span class="p">,</span> <span class="n">select_pair</span> <span class="o">=</span> <span class="n">record</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">For simulated y value: </span><span class="si">%s</span><span class="s2"> &amp; Selected pair: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">sim_y</span><span class="p">,</span> <span class="n">select_pair</span><span class="p">))</span>

        <span class="n">obs_y_df</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">observed_y</span><span class="p">[</span><span class="n">select_pair</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">obs_column_names</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">original_obs</span> <span class="ow">is</span> <span class="n">plot_observed_y_given_parameters</span><span class="o">.</span><span class="vm">__defaults__</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="n">original_obs_column_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">name</span><span class="p">:</span><span class="sa">f</span><span class="s1">&#39;*</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">obs_column_names</span><span class="p">))</span>
            
            <span class="n">original_obs_df</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">original_obs</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">original_obs_column_names</span><span class="p">)</span>
            <span class="n">obs_y_df</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">obs_y_df</span><span class="p">,</span> <span class="n">original_obs_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Note: Legend *Dog_X corresponds to &#39;y&#39; i.e.,original observation values&quot;</span><span class="p">)</span>
        
        <span class="n">obs_y_title</span><span class="o">=</span> <span class="s2">&quot;Observed values distribution for all dogs given parameter </span><span class="si">%s</span><span class="s2"> from </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">select_pair</span><span class="p">,</span> <span class="n">chain</span><span class="p">)</span>
        <span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">obs_y_df</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="n">obs_y_title</span><span class="p">)</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">obs_y_title</span><span class="p">,</span> <span class="n">xaxis_title</span><span class="o">=</span><span class="s2">&quot;Trials&quot;</span><span class="p">,</span> <span class="n">yaxis_title</span><span class="o">=</span><span class="s2">&quot;Probability of shock at trial j (𝜋𝑗)&quot;</span><span class="p">,</span> <span class="n">legend_title</span><span class="o">=</span><span class="s2">&quot;Dog identifier&quot;</span><span class="p">)</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Also Optionally pass the <code class="docutils literal notranslate"><span class="pre">True</span> <span class="pre">observed</span> <span class="pre">y</span></code> values to <code class="docutils literal notranslate"><span class="pre">original_obs</span></code> argument for all 30 dogs to plot alongside the <code class="docutils literal notranslate"><span class="pre">observed</span> <span class="pre">y</span></code> from alpha-beta pairs of interest.</strong></p>
<p><strong><em>Note</em></strong>: <code class="docutils literal notranslate"><span class="pre">True</span> <span class="pre">observed</span> <span class="pre">y</span></code> are marked with legends in format <code class="docutils literal notranslate"><span class="pre">*Dog_X</span></code></p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Following is an interactive plot, can be visualised Only in Binder.</p>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
<span class="n">plot_observed_y_given_parameters</span><span class="p">(</span><span class="n">lowest_obs</span><span class="p">,</span> <span class="n">selected_pairs</span><span class="p">,</span> <span class="n">obs_y_dict</span><span class="p">,</span> <span class="n">chain</span><span class="p">,</span> <span class="n">original_obs</span><span class="o">=</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Following plots a single scatterplots for comparison of <code class="docutils literal notranslate"><span class="pre">observed</span> <span class="pre">y</span></code> values for all alpha-beta pairs of interest from dense region in contourplot above, that is <code class="docutils literal notranslate"><span class="pre">-0.2</span> <span class="pre">&lt;</span> <span class="pre">alpha</span> <span class="pre">&lt;</span> <span class="pre">-0.19</span></code>, <code class="docutils literal notranslate"><span class="pre">-0.0075</span> <span class="pre">&lt;</span> <span class="pre">beta</span> <span class="pre">&lt;</span> <span class="pre">-0.0055</span></code></strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compare_dogs_given_parameters</span><span class="p">(</span><span class="n">pairs_to_compare</span><span class="p">,</span> <span class="n">observed_y</span><span class="p">,</span> <span class="n">original_obs</span><span class="o">=</span><span class="p">[],</span> <span class="n">alpha_by_beta_dict</span><span class="o">=</span> <span class="p">{}):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    </span>
<span class="sd">    Input</span>
<span class="sd">    --------</span>
<span class="sd">    </span>
<span class="sd">    pairs_to_compare: list of alpha, beta pair tuples to compare, </span>
<span class="sd">                      example :  [(-0.225, -0.0127), (-0.218, -0.0144)]</span>
<span class="sd">    observed_y: dict holding observed values correspodning to pair of alpha,</span>
<span class="sd">                      beta tuple as key, example: {(-0.225, -0.01272): tensor([[1.0000, 0.9874,..]])} </span>
<span class="sd">    alpha_by_beta_dict: holds alpha, beta pair tuples as keys &amp; alpha/beta as value, example:</span>
<span class="sd">                        {(-0.2010, -0.0018): 107.08}</span>
<span class="sd">    </span>
<span class="sd">    </span>
<span class="sd">    Output</span>
<span class="sd">    --------</span>
<span class="sd">    returns a plotly scatter plot with number of trials on X axis &amp; corresponding probability of getting</span>
<span class="sd">    shocked for each pair of (alpha, beta) passed for comparison.</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">combined_pairs_obs_df</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="n">title_txt</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="n">additional_txt</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="n">obs_column_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;Dog_</span><span class="si">{</span><span class="n">ind</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dogs_data</span><span class="p">[</span><span class="s2">&quot;Ndogs&quot;</span><span class="p">])]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">select_pair</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pairs_to_compare</span><span class="p">):</span>
        <span class="n">i</span><span class="o">+=</span><span class="mi">1</span>
        <span class="n">title_txt</span><span class="o">+=</span><span class="sa">f</span><span class="s1">&#39;Dog_X_m_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> corresponds to </span><span class="si">{</span><span class="n">select_pair</span><span class="si">}</span><span class="s1">, &#39;</span>

        <span class="n">obs_column_names_model_x</span> <span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">name</span><span class="p">:</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">_m_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">obs_column_names</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">alpha_by_beta_dict</span><span class="p">:</span>
            <span class="n">additional_txt</span><span class="o">+=</span><span class="sa">f</span><span class="s1">&#39;𝛼/𝛽 for Dog_X_m_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">alpha_by_beta_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">select_pair</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s1">, &#39;</span>
        
        <span class="n">obs_y_df</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">observed_y</span><span class="p">[</span><span class="n">select_pair</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">obs_column_names_model_x</span><span class="p">)</span>

        <span class="n">combined_pairs_obs_df</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">combined_pairs_obs_df</span><span class="p">,</span> <span class="n">obs_y_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">title_txt</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="n">additional_txt</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">original_obs</span> <span class="ow">is</span> <span class="n">compare_dogs_given_parameters</span><span class="o">.</span><span class="vm">__defaults__</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="n">original_obs_column_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">name</span><span class="p">:</span><span class="sa">f</span><span class="s1">&#39;*</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">obs_column_names</span><span class="p">))</span>

        <span class="n">original_obs_df</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">original_obs</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">original_obs_column_names</span><span class="p">)</span>
        <span class="n">combined_pairs_obs_df</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">combined_pairs_obs_df</span><span class="p">,</span> <span class="n">original_obs_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Note: Legend *Dog_X_ corresponds to &#39;y&#39; i.e.,original observation values&quot;</span><span class="p">)</span>
        
    <span class="n">obs_y_title</span><span class="o">=</span> <span class="s2">&quot;Observed values for all dogs given parameter for a chain&quot;</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">combined_pairs_obs_df</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="n">obs_y_title</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">obs_y_title</span><span class="p">,</span> <span class="n">xaxis_title</span><span class="o">=</span><span class="s2">&quot;Trials&quot;</span><span class="p">,</span> <span class="n">yaxis_title</span><span class="o">=</span><span class="s2">&quot;Probability of shock at trial j (𝜋𝑗)&quot;</span><span class="p">,</span> <span class="n">legend_title</span><span class="o">=</span><span class="s2">&quot;Dog identifier&quot;</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Also Optionally pass the <code class="docutils literal notranslate"><span class="pre">True</span> <span class="pre">observed</span> <span class="pre">y</span></code> values to <code class="docutils literal notranslate"><span class="pre">original_obs</span></code> argument for all 30 dogs to plot alongside the <code class="docutils literal notranslate"><span class="pre">observed</span> <span class="pre">y</span></code> from alpha-beta pairs of interest.</strong></p>
<p><strong><em>Note</em></strong>: <code class="docutils literal notranslate"><span class="pre">True</span> <span class="pre">observed</span> <span class="pre">y</span></code> are marked with legends in format <code class="docutils literal notranslate"><span class="pre">*Dog_X</span></code></p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Following is an interactive plot, can be visualised Only in Binder.</p>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
<span class="n">compare_dogs_given_parameters</span><span class="p">(</span><span class="n">selected_pairs</span><span class="p">,</span> <span class="n">obs_y_dict</span><span class="p">,</span> <span class="n">original_obs</span><span class="o">=</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Observations:</strong> The 3 individual scatter plots above correspond to 3 most optimum alpha-beta pairs from 3rd quadrant of contour plot drawn earlier; Also the scatterplot following them faciliates comparing obeserved y values for all 3 pairs at once:</p>
<p>Data for almost all dogs in the experiment favours m1 parameters (-0.19852, -0.0156), over m3 &amp; m2; With exceptions of Dog 6, 7 showing affinity to m3 parameters (-0.19804, -0.01568), over m2 &amp; m1 at all levels of 30 trials.</p>
<p><strong>Plotting observed values y corresponding to pairs of alpha-beta with with <code class="docutils literal notranslate"><span class="pre">mean,</span> <span class="pre">minmum,</span> <span class="pre">maximum</span> <span class="pre">value</span> <span class="pre">of</span></code> <span class="math notranslate nohighlight">\(\frac{alpha}{beta}\)</span></strong></p>
<p><strong>Following computes <span class="math notranslate nohighlight">\(\frac{alpha}{beta}\)</span> for each pair of alpha, beta and outputs pairs with <code class="docutils literal notranslate"><span class="pre">mean,</span> <span class="pre">maximum</span> <span class="pre">&amp;</span> <span class="pre">minimum</span> <span class="pre">values</span></code>; that can therefore be marked on a single scatterplots for comparison of observed y values for all alpha-beta pairs of interest</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_alpha_by_beta_records</span><span class="p">(</span><span class="n">chain_df</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">]):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    </span>
<span class="sd">    Input</span>
<span class="sd">    --------</span>
<span class="sd">    chain_df: dataframe holding sampled parameters for a given chain</span>
<span class="sd">    </span>
<span class="sd">    returns an alpha_by_beta_dictionary with alpha, beta pair tuples as keys &amp; alpha/beta as value,</span>
<span class="sd">    example: {(-0.2010, -0.0018): 107.08}</span>
<span class="sd">    </span>
<span class="sd">    Output</span>
<span class="sd">    -------</span>
<span class="sd">    Return a dictionary with values corresponding to statistics/metrics asked in argument metrics, computed</span>
<span class="sd">    over alpha_by_beta column of passed dataframe.</span>
<span class="sd">    </span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">alpha_beta_dict</span><span class="o">=</span> <span class="p">{}</span>
    
    <span class="n">chain_df</span><span class="p">[</span><span class="s2">&quot;alpha_by_beta&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">chain_df</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">chain_df</span><span class="p">[</span><span class="s2">&quot;beta&quot;</span><span class="p">]</span>
    <span class="n">min_max_values</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">chain_df</span><span class="p">[</span><span class="s2">&quot;alpha_by_beta&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
    <span class="n">alpha_beta_list</span><span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">key</span><span class="p">:</span> <span class="n">chain_df</span><span class="p">[</span><span class="n">chain_df</span><span class="p">[</span><span class="s2">&quot;alpha_by_beta&quot;</span><span class="p">]</span><span class="o">&lt;=</span><span class="n">min_max_values</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">)]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">([</span><span class="s2">&quot;alpha_by_beta&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">iloc</span><span class="p">[[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">set_index</span><span class="p">([</span><span class="s2">&quot;alpha&quot;</span><span class="p">,</span> <span class="s2">&quot;beta&quot;</span><span class="p">])[</span><span class="s2">&quot;alpha_by_beta&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span> <span class="n">metrics</span><span class="p">))</span>

    <span class="p">[</span><span class="n">alpha_beta_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">element</span><span class="p">)</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">alpha_beta_list</span><span class="p">];</span>
    <span class="k">return</span> <span class="n">alpha_beta_dict</span>


<span class="n">alpha_by_beta_dict</span> <span class="o">=</span> <span class="n">get_alpha_by_beta_records</span><span class="p">(</span><span class="n">chain_samples_df</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">])</span><span class="c1"># outputs a dict of type {(-0.2010, -0.0018): 107.08}</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Alpha-beta pair with value as alpha/beta: &quot;</span><span class="p">,</span> <span class="n">alpha_by_beta_dict</span><span class="p">)</span>


<span class="n">alpha_by_beta_selected_pairs</span><span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">alpha_by_beta_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">alpha_by_beta_obs_y_dict</span> <span class="o">=</span> <span class="n">get_obs_y_dict</span><span class="p">(</span><span class="n">alpha_by_beta_selected_pairs</span><span class="p">,</span> <span class="n">x_avoidance</span><span class="p">,</span> <span class="n">x_shocked</span><span class="p">)</span><span class="c1"># Outputs observed_values for given (alpha, beta)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Following is the scatter plot for <code class="docutils literal notranslate"><span class="pre">observed</span> <span class="pre">y</span></code> values corresponding to pairs of <code class="docutils literal notranslate"><span class="pre">alpha,</span> <span class="pre">beta</span></code> yielding <code class="docutils literal notranslate"><span class="pre">minimum,</span> <span class="pre">maximum</span> <span class="pre">&amp;</span> <span class="pre">mean</span></code> value for <span class="math notranslate nohighlight">\(\frac{alpha}{beta}\)</span>.</strong></p>
<p><strong><em>Note</em></strong>: The y i.e., original observations are simultaneously plotted side by side.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Following is an interactive plot, can be visualised Only in Binder.</p>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">compare_dogs_given_parameters</span><span class="p">(</span><span class="n">alpha_by_beta_selected_pairs</span><span class="p">,</span> <span class="n">alpha_by_beta_obs_y_dict</span><span class="p">,</span> 
                              <span class="n">original_obs</span><span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">alpha_by_beta_dict</span><span class="o">=</span> <span class="n">alpha_by_beta_dict</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Observations:</strong> The scatter plots above corresponds to 3 pairs of alpha-beta values from contour plot drawn earlier, which correspond to maxmimum, minimum &amp; mean value of 𝛼/𝛽. Plot faciliates comparing <code class="docutils literal notranslate"><span class="pre">obeserved</span> <span class="pre">y</span></code> values for all pairs with <code class="docutils literal notranslate"><span class="pre">True</span> <span class="pre">observed</span> <span class="pre">y</span></code> at once:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1. Data for for first 7 dogs in the experiment favours m1 parameters (-0.184, -0.0015) with highest 𝛼/𝛽 around 116, followed by m3 &amp; m2 at all levels of 30 trials. Avoidance learning in these 7 dogs is captured suitablely by model 2 but most of the instances for which they are shocked, are modelled well with m1 parameters.

2. Data for for rest 23 dogs in the experiment showed affinity for m2 parameters (-0.197, -0.016) with lowest 𝛼/𝛽 around 11, followed by m3 &amp; m1 at all levels of 30 trials; Likewise Avoidance learning in these 23 dogs is captured suitablely by model 2 but most of the instances for which they are shocked, are modelled well with m1 parameters only.

3. Data for Dogs 18-20 fits model 2 increasingly well after 10th trial; Whereas for Dogs 21-30 model 2 parameters fit the original data exceptionally well after 6th trial only.
</pre></div>
</div>
</div>
<div class="section" id="model-comparison">
<h2>6. Model Comparison<a class="headerlink" href="#model-comparison" title="Permalink to this headline">¶</a></h2>
<p><strong>Compare Dogs model with Normal prior &amp; Uniform prior using Deviance Information Criterion (DIC)</strong></p>
<p><strong>DIC is computed as follows</strong></p>
<p><span class="math notranslate nohighlight">\(D(\alpha,\beta) = -2\ \sum_{i=1}^{n} \log P\ (y_{i}\ /\ \alpha,\beta)\)</span></p>
<p><span class="math notranslate nohighlight">\(\log P\ (y_{i}\ /\ \alpha,\beta)\)</span> is the log likehood of shocks/avoidances observed given parameter <span class="math notranslate nohighlight">\(\alpha,\beta\)</span>, this expression expands as follows:</p>
<div class="math notranslate nohighlight">
\[D(\alpha,\beta) = -2\ \sum_{i=1}^{30}[ y_{i}\ (\alpha Xa_{i}\ +\beta\ Xs_{i}) + \ (1-y_{i})\log\ (1\ -\ e^{(\alpha Xa_{i}\ +\beta\ Xs_{i})})]\]</div>
<div class="section" id="using-d-alpha-beta-to-compute-dic">
<h3>Using <span class="math notranslate nohighlight">\(D(\alpha,\beta)\)</span> to Compute DIC<a class="headerlink" href="#using-d-alpha-beta-to-compute-dic" title="Permalink to this headline">¶</a></h3>
<p><span class="math notranslate nohighlight">\(\overline D(\alpha,\beta) = \frac{1}{T} \sum_{t=1}^{T} D(\alpha,\beta)\)</span></p>
<p><span class="math notranslate nohighlight">\(\overline \alpha = \frac{1}{T} \sum_{t=1}^{T}\alpha_{t}\\\)</span>
<span class="math notranslate nohighlight">\(\overline \beta = \frac{1}{T} \sum_{t=1}^{T}\beta_{t}\)</span></p>
<p><span class="math notranslate nohighlight">\(D(\overline\alpha,\overline\beta) = -2\ \sum_{i=1}^{30}[ y_{i}\ (\overline\alpha Xa_{i}\ +\overline\beta\ Xs_{i}) + \ (1-y_{i})\log\ (1\ -\ e^{(\overline\alpha Xa_{i}\ +\overline\beta\ Xs_{i})})]\)</span></p>
<p><strong>Therefore finally</strong>
$<span class="math notranslate nohighlight">\(
DIC\ =\ 2\ \overline D(\alpha,\beta)\ -\ D(\overline\alpha,\overline\beta)
\)</span>$</p>
<p><strong>Following method computes deviance value given parameters <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">&amp;</span> <span class="pre">beta</span></code></strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calculate_deviance_given_param</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">x_avoidance</span><span class="p">,</span> <span class="n">x_shocked</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Input</span>
<span class="sd">    -------</span>
<span class="sd">    parameters : dictionary containing sampled values of parameters alpha &amp; beta</span>
<span class="sd">    x_avoidance: tensor holding avoidance count for all dogs &amp; all trials, example for </span>
<span class="sd">                 30 dogs &amp; 25 trials, shaped (30, 25)</span>
<span class="sd">    x_shocked:   tensor holding shock count for all dogs &amp; all trials, example for 30 dogs</span>
<span class="sd">                 &amp; 25 trials, shaped (30, 25).</span>
<span class="sd">    y:           tensor holding response for all dogs &amp; trials, example for 30 dogs</span>
<span class="sd">                 &amp; 25 trials, shaped (30, 25).</span>
<span class="sd">    </span>

<span class="sd">    Output</span>
<span class="sd">    -------</span>
<span class="sd">    Computes deviance as D(Bt)</span>
<span class="sd">    D(Bt)   : Summation of log likelihood / conditional probability of output, </span>
<span class="sd">              given param &#39;Bt&#39; over all the &#39;n&#39; cases.</span>

<span class="sd">    Returns deviance value for a pair for parameters, alpha &amp; beta.</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">D_bt_</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">]</span><span class="o">*</span><span class="n">x_avoidance</span> <span class="o">+</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;beta&quot;</span><span class="p">]</span><span class="o">*</span><span class="n">x_shocked</span><span class="c1"># alpha * Xai + beta * Xsi</span>
    <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">double</span><span class="p">()</span>
    <span class="n">p</span><span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">p</span><span class="o">&lt;-</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0001</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    
    <span class="n">Pij_vec</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="c1"># shapes (750, 1)</span>
    <span class="n">Yij_vec</span><span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="c1"># shapes (1, 750)</span>
    
    <span class="c1"># D_bt = -2 * Summation_over_i-30 (yi.(alpha.Xai + beta.Xsi)+ (1-yi).log (1- e^(alpha.Xai + beta.Xsi)))</span>
    <span class="n">D_bt</span><span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">Yij_vec</span><span class="p">,</span> <span class="n">Pij_vec</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">Yij_vec</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">Pij_vec</span><span class="p">)))</span>
    <span class="n">D_bt</span><span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">D_bt</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">D_bt</span>

<span class="k">def</span> <span class="nf">calculate_mean_deviance</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">x_avoidance</span><span class="p">,</span> <span class="n">x_shocked</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    </span>
<span class="sd">    Input</span>
<span class="sd">    -------</span>
<span class="sd">    samples : dictionary containing mean of sampled values of parameters alpha &amp; beta.</span>
<span class="sd">    x_avoidance: tensor holding avoidance count for all dogs &amp; all trials, example for </span>
<span class="sd">                 30 dogs &amp; 25 trials, shaped (30, 25).</span>
<span class="sd">    x_shocked:   tensor holding shock count for all dogs &amp; all trials, example for 30 dogs</span>
<span class="sd">                 &amp; 25 trials, shaped (30, 25).</span>
<span class="sd">    y:           tensor holding response for all dogs &amp; trials, example for 30 dogs</span>
<span class="sd">                 &amp; 25 trials, shaped (30, 25).</span>

<span class="sd">    </span>
<span class="sd">    Output</span>
<span class="sd">    -------</span>
<span class="sd">    Computes mean deviance as D(Bt)_bar</span>
<span class="sd">    D(Bt)_bar: Average of D(Bt) values calculated for each </span>
<span class="sd">                   Bt (Bt is a single param value from chain of samples)</span>
<span class="sd">    Returns mean deviance value for a pair for parameters, alpha &amp; beta.</span>
<span class="sd">    </span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">samples_count</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">all_D_Bts</span><span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">samples_count</span><span class="p">):</span><span class="c1"># pair of alpha, beta</span>
        <span class="n">samples_</span><span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">param</span><span class="p">:</span> <span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">samples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">param</span><span class="p">)[</span><span class="n">index</span><span class="p">]),</span> <span class="n">samples</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
        
        <span class="n">D_Bt</span><span class="o">=</span> <span class="n">calculate_deviance_given_param</span><span class="p">(</span><span class="n">samples_</span><span class="p">,</span> <span class="n">x_avoidance</span><span class="p">,</span> <span class="n">x_shocked</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">all_D_Bts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">D_Bt</span><span class="p">)</span>
    
    <span class="n">D_Bt_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">all_D_Bts</span><span class="p">))</span>
    
    <span class="n">D_Bt_mean</span> <span class="o">=</span><span class="n">D_Bt_mean</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">D_Bt_mean</span>
        
</pre></div>
</div>
</div>
</div>
<p><strong>Following method computes <code class="docutils literal notranslate"><span class="pre">deviance</span> <span class="pre">information</span> <span class="pre">criterion</span></code> for a given bayesian model &amp; chains of sampled parameters <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">&amp;</span> <span class="pre">beta</span></code></strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">DIC</span><span class="p">(</span><span class="n">sample_chains</span><span class="p">,</span> <span class="n">x_avoidance</span><span class="p">,</span> <span class="n">x_shocked</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        </span>
<span class="sd">    Input</span>
<span class="sd">    -------</span>
<span class="sd">    sample_chains : dictionary containing multiple chains of sampled values, with chain name as</span>
<span class="sd">                    key and sampled values of parameters alpha &amp; beta.</span>
<span class="sd">    x_avoidance: tensor holding avoidance count for all dogs &amp; all trials, example for </span>
<span class="sd">                 30 dogs &amp; 25 trials, shaped (30, 25).</span>
<span class="sd">    x_shocked:   tensor holding shock count for all dogs &amp; all trials, example for 30 dogs</span>
<span class="sd">                 &amp; 25 trials, shaped (30, 25).</span>
<span class="sd">    y:           tensor holding response for all dogs &amp; trials, example for 30 dogs</span>
<span class="sd">                 &amp; 25 trials, shaped (30, 25).</span>
<span class="sd">            </span>
<span class="sd">    Output</span>
<span class="sd">    -------</span>
<span class="sd">    Computes DIC as follows</span>
<span class="sd">    D_mean_parameters: 𝐷(𝛼_bar,𝛽_bar), Summation of log likelihood / conditional probability of output, </span>
<span class="sd">                   given average of each param 𝛼, 𝛽, over &#39;s&#39; samples, across all the &#39;n&#39; cases.</span>
<span class="sd">    D_Bt_mean: 𝐷(𝛼,𝛽)_bar, Summation of log likelihood / conditional probability of output, </span>
<span class="sd">                   given param 𝛼, 𝛽, across all the &#39;n&#39; cases.</span>
<span class="sd">        </span>
<span class="sd">    𝐷𝐼𝐶 is computed as 𝐷𝐼𝐶 = 2 𝐷(𝛼,𝛽)_bar − 𝐷(𝛼_bar,𝛽_bar)</span>
<span class="sd">    </span>
<span class="sd">    returns Deviance Information Criterion for a chain alpha &amp; beta sampled values.</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dic_list</span><span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">chain</span><span class="p">,</span> <span class="n">samples</span> <span class="ow">in</span> <span class="n">sample_chains</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">samples</span><span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">param</span><span class="p">:</span> <span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">param</span><span class="p">))),</span> <span class="n">samples</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span><span class="c1"># np array to tensors</span>

        <span class="n">mean_parameters</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">param</span><span class="p">:</span> <span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">param</span><span class="p">))),</span> <span class="n">samples</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
        <span class="n">D_mean_parameters</span> <span class="o">=</span> <span class="n">calculate_deviance_given_param</span><span class="p">(</span><span class="n">mean_parameters</span><span class="p">,</span> <span class="n">x_avoidance</span><span class="p">,</span> <span class="n">x_shocked</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="n">D_Bt_mean</span> <span class="o">=</span> <span class="n">calculate_mean_deviance</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">x_avoidance</span><span class="p">,</span> <span class="n">x_shocked</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">dic</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span> <span class="n">D_Bt_mean</span> <span class="o">-</span> <span class="n">D_mean_parameters</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
        <span class="n">dic_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dic</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;. . .DIC for </span><span class="si">%s</span><span class="s2">: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">chain</span><span class="p">,</span> <span class="n">dic</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">. .Mean Deviance information criterion for all chains: </span><span class="si">%s</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dic_list</span><span class="p">),</span> <span class="mi">3</span><span class="p">)))</span>

<span class="k">def</span> <span class="nf">compare_DICs_given_model</span><span class="p">(</span><span class="n">x_avoidance</span><span class="p">,</span> <span class="n">x_shocked</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    </span>
<span class="sd">    Input</span>
<span class="sd">    --------</span>
<span class="sd">    x_avoidance: tensor holding avoidance count for all dogs &amp; all trials, example for </span>
<span class="sd">                 30 dogs &amp; 25 trials, shaped (30, 25).</span>
<span class="sd">    x_shocked:   tensor holding shock count for all dogs &amp; all trials, example for 30 dogs</span>
<span class="sd">                 &amp; 25 trials, shaped (30, 25).</span>
<span class="sd">    y:           tensor holding response for all dogs &amp; trials, example for 30 dogs</span>
<span class="sd">                 &amp; 25 trials, shaped (30, 25).</span>
<span class="sd">    kwargs: dict of type {&quot;model_name&quot;: sample_chains_dict}</span>
<span class="sd">    </span>
<span class="sd">    Output</span>
<span class="sd">    --------</span>
<span class="sd">    Compares Deviance Information Criterion value for a multiple bayesian models.</span>
<span class="sd">    </span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">sample_chains</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="se">\n\n</span><span class="s2">For model : </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="o">*</span><span class="mi">30</span><span class="p">,</span> <span class="n">model_name</span><span class="p">))</span>
        <span class="n">DIC</span><span class="p">(</span><span class="n">sample_chains</span><span class="p">,</span> <span class="n">x_avoidance</span><span class="p">,</span> <span class="n">x_shocked</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Define alternate model with different prior such as uniform distribution</strong></p>
<p>The following model is defined in the same manner using Pyro as per the following expression of generative model for this dataset, just with modification of prior distribution to <code class="docutils literal notranslate"><span class="pre">Uniform</span></code> rather than <code class="docutils literal notranslate"><span class="pre">Normal</span></code> as follows:</p>
<p><span class="math notranslate nohighlight">\(\pi_j\)</span>  ~   <span class="math notranslate nohighlight">\(bern\ (\exp \ (\alpha.XAvoidance + \beta.XShocked)\ )\)</span>,  <span class="math notranslate nohighlight">\(prior\ \alpha\)</span> ~ <span class="math notranslate nohighlight">\(U(0., 316.)\)</span>,  <span class="math notranslate nohighlight">\(\beta\)</span> ~ <span class="math notranslate nohighlight">\(U(0., 316.)\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dogs model with uniform prior</span>
<span class="k">def</span> <span class="nf">DogsModelUniformPrior</span><span class="p">(</span><span class="n">x_avoidance</span><span class="p">,</span> <span class="n">x_shocked</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Input</span>
<span class="sd">    -------</span>
<span class="sd">    x_avoidance: tensor holding avoidance count for all dogs &amp; all trials, example for </span>
<span class="sd">                 30 dogs &amp; 25 trials, shaped (30, 25)</span>
<span class="sd">    x_shocked:   tensor holding shock count for all dogs &amp; all trials, example for 30 dogs</span>
<span class="sd">                 &amp; 25 trials, shaped (30, 25).</span>
<span class="sd">    y:           tensor holding response for all dogs &amp; trials, example for 30 dogs</span>
<span class="sd">                 &amp; 25 trials, shaped (30, 25).</span>
<span class="sd">    </span>
<span class="sd">    Output</span>
<span class="sd">    --------</span>
<span class="sd">    Implements pystan model: {</span>
<span class="sd">              alpha ~ uniform(0.0, 316.2);</span>
<span class="sd">              beta  ~ uniform(0.0, 316.2);</span>
<span class="sd">              for(dog in 1:Ndogs)  </span>
<span class="sd">                for (trial in 2:Ntrials)  </span>
<span class="sd">                  y[dog, trial] ~ bernoulli(exp(alpha * xa[dog, trial] + beta * xs[dog, trial]));}</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;alpha&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00001</span><span class="p">))</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;beta&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00001</span><span class="p">))</span>
    <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">):</span>
        <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;obs&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">alpha</span><span class="o">*</span><span class="n">x_avoidance</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">x_shocked</span><span class="p">)),</span> <span class="n">obs</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="n">hmc_sample_chains_uniform_prior</span><span class="o">=</span> <span class="n">get_hmc_n_chains</span><span class="p">(</span><span class="n">DogsModelUniformPrior</span><span class="p">,</span> <span class="n">x_avoidance</span><span class="p">,</span> <span class="n">x_shocked</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">num_chains</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">base_count</span> <span class="o">=</span> <span class="mi">900</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>compute &amp; compare <code class="docutils literal notranslate"><span class="pre">deviance</span> <span class="pre">information</span> <span class="pre">criterion</span></code> for a multiple bayesian models</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">compare_DICs_given_model</span><span class="p">(</span><span class="n">x_avoidance</span><span class="p">,</span> <span class="n">x_shocked</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">Dogs_normal_prior</span><span class="o">=</span> <span class="n">hmc_sample_chains</span><span class="p">,</span> <span class="n">Dogs_uniform_prior</span><span class="o">=</span> <span class="n">hmc_sample_chains_uniform_prior</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "pytorch_x86"
        },
        kernelOptions: {
            kernelName: "pytorch_x86",
            path: "./Part_II/Chapter_1/md_files"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'pytorch_x86'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    

</div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Prakash Bisht, Soma S. Dhavala<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>